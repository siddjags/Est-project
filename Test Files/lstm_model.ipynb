{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import *\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no2 = 6\n",
    "uvpm = 14\n",
    "with open('airquality17-20.csv', 'r') as csvfile:\n",
    "    uvpm_col = []\n",
    "    no2_col = []\n",
    "    for line in csvfile.readlines():\n",
    "        array = line.split(',')\n",
    "        new_str = array[14].rstrip(\"\\n\")\n",
    "        new_no2 = array[no2]\n",
    "        if new_str == '':\n",
    "            new_str = '0'\n",
    "        uvpm_col.append(new_str)\n",
    "        no2_col.append(new_no2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del uvpm_col[0]\n",
    "del no2_col[0]\n",
    "\n",
    "int_uvpm_col = []\n",
    "float_no2_col = []\n",
    "for item in uvpm_col:\n",
    "    new_item = int(item)\n",
    "    int_uvpm_col.append(new_item)\n",
    "for item in no2_col:\n",
    "    \n",
    "    new_item = float(item)\n",
    "    float_no2_col.append(new_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = []\n",
    "feat = []\n",
    "in_data = 120\n",
    "out_data = 10\n",
    "\n",
    "for i in range(0,len(float_no2_col)-in_data-out_data+1):\n",
    "    feat.append(float_no2_col[i:i+in_data])\n",
    "    label.append(float_no2_col[i+in_data:i+in_data+out_data])\n",
    "\n",
    "total_len = len(feat)\n",
    "train_feature = feat[0:total_len-1-300] \n",
    "train_label = label[0:total_len-1-300]\n",
    "dev_feature = feat[total_len-300:total_len-1]\n",
    "dev_label = label[total_len-300:total_len-1]\n",
    "test_feature = float_no2_col[len(float_no2_col)-1-120:len(float_no2_col)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class No2Dataset(Dataset):\n",
    "    def __init__(self, feature, label):\n",
    "        self.labels = label\n",
    "        self.feature = feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.feature[index]\n",
    "        y = self.label[index]\n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class lstm_model(nn.Module):\n",
    "    def __init__(self, in_day, out_day, hidden_size):\n",
    "        super(lstm_model, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=in_day, hidden_size = hidden_size, \n",
    "                            num_layers=2, dropout=0.2, bidirectional= True)\n",
    "        self.linear =nn.Linear(hidden_size*2, hidden_size*2)\n",
    "        self.droupout = nn.Dropout(0.2)\n",
    "        self.output = nn.Linear(hidden_size *2, out_day)\n",
    "    def forward(self, x):\n",
    "        out = self.lstm(out)[0]\n",
    "        out = self.linear(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.output(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, dev_loader, num_epoch):\n",
    "    model.train()\n",
    "    loss_val = [] \n",
    "    acc_val = []\n",
    "    for epoch in range(num_epoch):\n",
    "        print(\"Starting Epoch \", epoch+1)\n",
    "        avg_loss = 0.0\n",
    "        before = time.time()\n",
    "        for batch_num, (featrue, labels) in enumerate(train_loader):\n",
    "            feature, labels = feature.to(device), labels.to(device)\n",
    "            out = model(feature)\n",
    "            loss = criterion()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss +=loss.item()\n",
    "            \n",
    "            if batch_num%50 == 49:\n",
    "                print(\"Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}\"\n",
    "                     .format(epoch+1, batch_num+1, avg_loss/50))\n",
    "                avg_loss = 0.0\n",
    "                \n",
    "        after = time.time()\n",
    "        total = after - before\n",
    "        print(time.strftime(\"%H:%M:%S\",time.gmtime(total)))\n",
    "        val_loss, val_acc = test_predict(model, dev_loader)\n",
    "        loss_val.append(val_loss)\n",
    "        acc_val.append(val_acc)\n",
    "        print('Val Loss: {:.4f}\\tVal Accuracy: {:.4f}'.format(val_loss, val_acc))\n",
    "        scheduler.step()\n",
    "    return loss_val, acc_val\n",
    "        \n",
    "def test_predict(model, data_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        avg_loss = []\n",
    "        accuracy = []\n",
    "        print(\"Starting Dev Evaluation\")\n",
    "        for batch_num, (feature, labels) in enumerate(data_loader):\n",
    "            feature, labels = feature.to(device), labels.to(device)\n",
    "            out = model(feature)\n",
    "            loss = criterion\n",
    "            correct = 0\n",
    "            avg_loss/append(loss.item())\n",
    "            for i in range(len(out)):\n",
    "                if out[i] == labels[i]:\n",
    "                    correct +=1\n",
    "            correct = correct/len(out)\n",
    "            accuracy.append(correct)\n",
    "        model.train()\n",
    "        return np.mean(avg_loss), np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def real_predict(model, feature):\n",
    "    model.eval()\n",
    "    out = model(feature)\n",
    "    return out\n",
    "\n",
    "def train_predict(model, dataloader):\n",
    "    model.eval()\n",
    "    train_out = []\n",
    "    train_label = []\n",
    "    for batch_num, (feature, labels) in enumerate(dataloader):\n",
    "        feature, labels = feature.to(device), labels.to(device)\n",
    "        out = model(feature)\n",
    "        train_out.append(out)\n",
    "        train_label.append(labels)\n",
    "    \n",
    "    return train_out, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = No2Dataset(train_feature, train_label)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                             batch_size = 32,\n",
    "                             shuffle = True)\n",
    "\n",
    "dev_dataset = No2Dataset(dev_feature, dev_label)\n",
    "dev_dataloader = DataLoader(dataset=dev_dataset,\n",
    "                           batch_size = 32,\n",
    "                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "num_epoch = 30\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(11785)\n",
    "model = lstm_model(in_data, out_data, hidden_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-5)\n",
    "model.to(device)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_val, loss_acc = train(model, train_dataloader, dev_dataloader,30)\n",
    "train_out , train_labels = train_predict(model, train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
